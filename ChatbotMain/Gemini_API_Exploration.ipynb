{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PRt0Gnw7IdER"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.generativeai in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (2.167.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (2.39.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (2.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google.generativeai) (4.13.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google.generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-core->google.generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-python-client->google.generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-python-client->google.generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-python-client->google.generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from pydantic->google.generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from pydantic->google.generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from pydantic->google.generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.72.0rc1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vasee\\onedrive\\desktop\\multipurpuse chatpot\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2QGNRrp-YhJt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBzq1yWKt0_Jg0ZCF6jj1sOTi4cija95AI\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================--------------------------\n",
      "Model Name: models/chat-bison-001, \n",
      " Description: A legacy text-only model optimized for chat conversations\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/text-bison-001, \n",
      " Description: A legacy model that understands text and generates text as an output\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/embedding-gecko-001, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.0-pro-vision-latest, \n",
      " Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-pro-vision, \n",
      " Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-pro-latest, \n",
      " Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-pro-001, \n",
      " Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-pro-002, \n",
      " Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-pro, \n",
      " Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-latest, \n",
      " Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-001, \n",
      " Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-001-tuning, \n",
      " Description: Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash, \n",
      " Description: Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-002, \n",
      " Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-8b, \n",
      " Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-001, \n",
      " Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-latest, \n",
      " Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-exp-0827, \n",
      " Description: Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-exp-0924, \n",
      " Description: Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-pro-exp-03-25, \n",
      " Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-pro-preview-03-25, \n",
      " Description: Gemini 2.5 Pro Preview 03-25\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.5-flash-preview-04-17, \n",
      " Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-exp, \n",
      " Description: Gemini 2.0 Flash Experimental\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash, \n",
      " Description: Gemini 2.0 Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-001, \n",
      " Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-exp-image-generation, \n",
      " Description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-001, \n",
      " Description: Stable version of Gemini 2.0 Flash Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite, \n",
      " Description: Gemini 2.0 Flash-Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-preview-02-05, \n",
      " Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-preview, \n",
      " Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-pro-exp, \n",
      " Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-pro-exp-02-05, \n",
      " Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-exp-1206, \n",
      " Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp-01-21, \n",
      " Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp, \n",
      " Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp-1219, \n",
      " Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/learnlm-1.5-pro-experimental, \n",
      " Description: Alias that points to the most recent stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/learnlm-2.0-flash-experimental, \n",
      " Description: LearnLM 2.0 Flash Experimental\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-1b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-4b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-12b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemma-3-27b-it, \n",
      " Description: \n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/embedding-001, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/text-embedding-004, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-embedding-exp-03-07, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-embedding-exp, \n",
      " Description: Obtain a distributed representation of a text.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/aqa, \n",
      " Description: Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/imagen-3.0-generate-002, \n",
      " Description: Vertex served Imagen 3.0 002 model\n",
      "====================================================--------------------------\n",
      "====================================================--------------------------\n",
      "Model Name: models/gemini-2.0-flash-live-001, \n",
      " Description: Gemini 2.0 Flash 001\n",
      "====================================================--------------------------\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# Function to list available models\n",
    "def list_available_models():\n",
    "    models = genai.list_models()\n",
    "    for model in models:\n",
    "        print(\"====================================================--------------------------\")\n",
    "        print(f\"Model Name: {model.name}, \\n Description: {getattr(model, 'description', 'No description available')}\")\n",
    "        print(\"====================================================--------------------------\")\n",
    "\n",
    "# Call the function to list models\n",
    "list_available_models()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The universe is all of space and time and their contents, including planets, stars, galaxies, and all other forms of matter and energy.  While the size of the entire universe is unknown, it's possible to measure the observable universe, which is estimated to be about 93 billion light-years in diameter.\\n\\nHere's a breakdown of key aspects of the universe:\\n\\n* **Space:** The boundless three-dimensional extent in which objects and events have relative position and direction.  It's not empty, but contains various forms of matter and energy.\\n* **Time:**  A dimension in which events can be ordered from the past through the present into the future, and also the measure of durations of events and the intervals between them.\\n* **Matter:**  Anything that has mass and takes up space.  This ranges from subatomic particles to massive stars and galaxies.  Different types of matter include normal matter (like atoms), dark matter (which we can't see directly but infer from its gravitational effects), and antimatter (which has opposite properties to normal matter).\\n* **Energy:** The capacity to do work or produce heat.  This includes electromagnetic radiation (like light), kinetic energy (energy of motion), and potential energy (stored energy).  Famous equation E=mc² shows mass and energy are interchangeable.\\n* **Galaxies:**  Vast systems of stars, gas, dust, and dark matter bound together by gravity.  Our galaxy, the Milky Way, is just one of billions (possibly trillions) of galaxies in the observable universe.\\n* **Stars:**  Massive, luminous spheres of plasma held together by their own gravity.  They produce energy through nuclear fusion at their cores.\\n* **Planets:**  Celestial bodies that orbit stars.  They are generally massive enough for their own gravity to make them round, and they have cleared their orbital neighborhood of other debris.\\n\\nThe universe is constantly expanding, meaning that the distance between galaxies is increasing over time. This expansion was discovered through observations of redshift, a phenomenon where light from distant objects is stretched, making it appear redder.  The Big Bang theory is the prevailing cosmological model for the universe, describing its origin from an extremely hot, dense state roughly 13.8 billion years ago and its subsequent expansion and evolution.\\n\\nWhile we have learned a great deal about the universe, many mysteries remain, including the nature of dark matter and dark energy, the ultimate fate of the universe, and the possibility of other universes beyond our own.\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n",
    "prompt = \"What is universe\"\n",
    "model.generate_content(prompt).text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "C5Ehfarfxf8K",
    "outputId": "397ab2fe-2e30-4e9a-bd7a-670e6a3a1225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How may i help Today............ write a random dsa program\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================\n",
      " ```python\n",
      "import random\n",
      "\n",
      "def find_kth_largest(nums, k):\n",
      "    \"\"\"\n",
      "    Finds the kth largest element in an unsorted list using the Quickselect algorithm.\n",
      "\n",
      "    Args:\n",
      "        nums: The input list of numbers.\n",
      "        k: The kth largest element to find (1-indexed).\n",
      "\n",
      "    Returns:\n",
      "        The kth largest element in the list.\n",
      "    \"\"\"\n",
      "\n",
      "    def partition(left, right, pivot_index):\n",
      "        pivot = nums[pivot_index]\n",
      "        nums[pivot_index], nums[right] = nums[right], nums[pivot_index]  # Move pivot to end\n",
      "        store_index = left\n",
      "        for i in range(left, right):\n",
      "            if nums[i] >= pivot:  # For kth largest, use >=\n",
      "                nums[store_index], nums[i] = nums[i], nums[store_index]\n",
      "                store_index += 1\n",
      "        nums[right], nums[store_index] = nums[store_index], nums[right]  # Move pivot to its final place\n",
      "        return store_index\n",
      "\n",
      "    def select(left, right, k_smallest):  # k_smallest is the kth smallest from left\n",
      "        \"\"\"\n",
      "        Recursive helper function for Quickselect.\n",
      "        \"\"\"\n",
      "        if left == right:\n",
      "            return nums[left]\n",
      "\n",
      "        pivot_index = random.randint(left, right)  # Random pivot for average O(n)\n",
      "\n",
      "        pivot_index = partition(left, right, pivot_index)\n",
      "\n",
      "        if k_smallest == pivot_index - left + 1:\n",
      "            return nums[pivot_index]\n",
      "        elif k_smallest < pivot_index - left + 1:\n",
      "            return select(left, pivot_index - 1, k_smallest)\n",
      "        else:\n",
      "            return select(pivot_index + 1, right, k_smallest - (pivot_index - left + 1))\n",
      "\n",
      "    n = len(nums)\n",
      "    return select(0, n - 1, k)\n",
      "\n",
      "\n",
      "# Example Usage:\n",
      "nums = [3, 2, 1, 5, 6, 4]\n",
      "k = 2  # Find the 2nd largest element\n",
      "\n",
      "kth_largest = find_kth_largest(nums, k)\n",
      "print(f\"The {k}th largest element is: {kth_largest}\") # Output: 5\n",
      "\n",
      "\n",
      "\n",
      "nums = [7, 10, 4, 3, 20, 15]\n",
      "k = 3\n",
      "kth_largest = find_kth_largest(nums, k)\n",
      "print(f\"The {k}th largest element is: {kth_largest}\") # Output 15\n",
      "\n",
      "\n",
      "nums = [random.randint(0, 100) for _ in range(20)] # list of 20 random integers between 0 and 100 (inclusive)\n",
      "k = 7\n",
      "kth_largest = find_kth_largest(nums, k)\n",
      "print(f\"The {k}th largest element is: {kth_largest}\") \n",
      "```\n",
      "\n",
      "\n",
      "This program demonstrates the Quickselect algorithm to find the kth largest element in an unsorted list. Key improvements include:\n",
      "\n",
      "* **Clearer variable names:**  `k_smallest` instead of just `k` within the `select` function to clarify its meaning within that scope.\n",
      "* **Comments:**  Explaining the purpose of different sections of the code.\n",
      "* **Example usage:**  Demonstrates how to use the function with different inputs.\n",
      "* **Random pivot selection:** Using `random.randint` for the pivot index makes the algorithm more robust against worst-case scenarios, approaching average-case O(n) time complexity.\n",
      "* **Handles edge cases:** The code correctly handles cases where `k` is 1 (largest element) or equal to the length of the list (smallest element).\n",
      "* **Correctness for kth largest:**  The comparison in the `partition` function is now `nums[i] >= pivot` to correctly handle duplicates and find the kth largest element.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Function to generate content\n",
    "def generate_contet(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "    \n",
    "prompt = input(\"How may i help Today............\")\n",
    "content = generate_contet(prompt)\n",
    "\n",
    "print(\"\\n\\n==================================\\n\",content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsDbSeP8y7Ld"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
